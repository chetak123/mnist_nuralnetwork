{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## writting simple nural network for mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import scipy.special #here its used for the activation function(writting clear sigmoid fun.)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nuralnetwork:\n",
    "    def __init__(self,inputnode,hiddennodes,outputnodes,learningrate):\n",
    "        self.inode=inputnode\n",
    "        self.onode=outputnodes\n",
    "        self.hnode=hiddennodes\n",
    "        self.lr=learningrate\n",
    "        \n",
    "        #declaration of input to hidden weights (wih) and hidden to output nodes (who) in form of matrices\n",
    "        #the wih matix has hnode rows and inode columns\n",
    "        self.wih=np.random.normal(0.0, pow(self.hnode, -0.5),(self.hnode, self.inode))\n",
    "        self.who=np.random.normal(0.0, pow(self.onode, -0.5),(self.onode, self.hnode))\n",
    "        \n",
    "        #writting the activation function\n",
    "        self.act_fun=lambda x:scipy.special.expit(x)\n",
    "        \n",
    "    def train(self,inputs_list,targets_list):\n",
    "        #convert list to 2D array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        #signals into and out of hidden layer nodes (in form of matrix)\n",
    "        hi_inp=np.dot(self.wih,inputs)\n",
    "        hi_out=self.act_fun(hi_inp)\n",
    "        #signals into and out of final layer\n",
    "        fi_inp=np.dot(self.who,hi_out)\n",
    "        fi_out=self.act_fun(fi_inp)\n",
    "        \n",
    "        output_err=targets-fi_out #error at output layer\n",
    "        hidd_err=np.dot(self.who.T,output_err) #hidden layer error is the output_err,split by weights,\n",
    "        #recombined at hidden nodes\n",
    "        #now we have reached the core or the heart of our network\n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who=self.who+self.lr*np.dot((output_err*fi_out*(1.0-fi_out)),np.transpose(hi_out))\n",
    "        # update the wight for links btw input layer and hidden layer\n",
    "        self.wih+=self.lr*np.dot((hidd_err*hi_out*(1.0-hi_out)),np.transpose(inputs))\n",
    "        \n",
    "    def query(self,inputs_list):\n",
    "        inputs=np.array(inputs_list,ndmin=2).T\n",
    "        \n",
    "        hi_inp=np.dot(self.wih,inputs)\n",
    "        hi_out=self.act_fun(hi_inp)\n",
    "        \n",
    "        fi_inp=np.dot(self.who,hi_out)\n",
    "        fi_out=self.act_fun(fi_inp)\n",
    "        \n",
    "        return (fi_out)\n",
    "    def exit_out(self):\n",
    "        return(self.wih,lambda x:scipy.special.expit(x),self.who)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "# learning rate is 0.3\n",
    "learning_rate = 0.3\n",
    "# create instance of neural network\n",
    "n = nuralnetwork(input_nodes,hidden_nodes,output_nodes,learning_rate)\n",
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_dataset/mnist_test.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "# train the neural network\n",
    "# go through all records in the training data set\n",
    "\n",
    "for record in training_data_list:    \n",
    "# split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "# scale and shift the inputs\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "# create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "    targets = np.zeros(output_nodes) + 0.0\n",
    "    # all_values[0] is the target label for this record\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    n.train(inputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_wih,x_act,x_who=n.exit_out()\n",
    "def nural(input_l):\n",
    "    x_act=lambda x:scipy.special.expit(x)\n",
    "    inp=np.array(input_l,ndmin=2).T\n",
    "    hi_i=np.dot(x_wih,input_l)\n",
    "    hi_o=x_act(hi_i)\n",
    "    fi_i=np.dot(x_who,hi_o)\n",
    "    fi_o=x_act(fi_i)\n",
    "    return (fi_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"mnist_dataset/mnist_test_10.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "all_val=test_data_list[3].split(',')\n",
    "print(all_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.30000998e-01, 1.00101861e-04, 3.95781537e-03, 4.07265296e-04,\n",
       "       1.89775509e-06, 1.16162535e-02, 2.13729765e-02, 2.49719384e-03,\n",
       "       5.39772593e-05, 5.05554691e-05])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nural((np.asfarray(all_val[1:])/255.0*0.99)+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.30000998e-01],\n",
       "       [1.00101861e-04],\n",
       "       [3.95781537e-03],\n",
       "       [4.07265296e-04],\n",
       "       [1.89775509e-06],\n",
       "       [1.16162535e-02],\n",
       "       [2.13729765e-02],\n",
       "       [2.49719384e-03],\n",
       "       [5.39772593e-05],\n",
       "       [5.05554691e-05]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query((np.asfarray(all_val[1:])/255.0*0.99)+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbbf61b0d50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_arr=(np.asfarray(all_val[1:]).reshape(28,28))\n",
    "plt.imshow(img_arr,cmap='Greys',interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# test the neural network\\n# scorecard for how well the network performs, initially empty\\nscorecard = []\\n# go through all the records in the test data set\\nfor record in test_data_list:\\n# split the record by the \\',\\' commas\\n    all_values = record.split(\\',\\')\\n    # correct answer is first value\\n    correct_label = int(all_values[0])\\n    #print(correct_label, \"correct label\")\\n    # scale and shift the inputs\\n    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\\n    # query the network\\n    outputs = n.query(inputs)\\n    # the index of the highest value corresponds to the label\\n    label = np.argmax(outputs)\\n    #print(label, \"network\\'s answer\")\\n    # append correct or incorrect to list\\n    if (label == correct_label):\\n    # network\\'s answer matches correct answer, add 1 to scorecard\\n        scorecard.append(1)\\n    else:\\n    # network\\'s answer doesn\\'t match correct answer, add 0 to scorecard\\n        scorecard.append(0)\\n        pass\\n    pass'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# test the neural network\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "# split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    #print(correct_label, \"correct label\")\n",
    "    # scale and shift the inputs\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = np.argmax(outputs)\n",
    "    #print(label, \"network's answer\")\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "    # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "    # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# calculate the performance score, the fraction of correct answers\\nscorecard_array = np.asarray(scorecard)\\nprint (\"performance = \", scorecard_array.sum() /scorecard_array.size)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() /scorecard_array.size)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "#import libraries\n",
    "import numpy as np\n",
    "import scipy.special #here its used for the activation function(writting clear sigmoid fun.)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#creating file path\n",
    "model_path=os.path.join(os.path.pardir,'models','model_reg.pkl') #path variable where file is stored\n",
    "model_pathwo=os.path.join(os.path.pardir,'models','model_who.pkl') #path variable where file is stored\n",
    "model_pathwi=os.path.join(os.path.pardir,'models','model_wih.pkl') #path variable where file is stored\n",
    "\n",
    "#open the file to write\n",
    "model_pickle = open(model_path, 'wb') #here wb means we are writting in binary to model_reg.pkl\n",
    "model_picklewo = open(model_pathwo, 'wb') #here wb means we are writting in binary to model_reg.pkl\n",
    "model_picklewi = open(model_pathwi, 'wb') #here wb means we are writting in binary to model_reg.pkl\n",
    "# persist the model in file\n",
    "\n",
    "pickle.dump(nural,model_pickle)\n",
    "x_wih,x_act,x_who\n",
    "pickle.dump(x_wih,model_picklewi)\n",
    "#pickle.dump(x_act,model_pickle)\n",
    "pickle.dump(x_who,model_picklewo)\n",
    "\n",
    "#close the file\n",
    "model_pickle.close()\n",
    "model_picklewi.close()\n",
    "model_picklewo.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nural(input_l):\n",
    "    x_act=lambda x:scipy.special.expit(x)\n",
    "    inp=np.array(input_l,ndmin=2).T\n",
    "    hi_i=np.dot(x_wih,input_l)\n",
    "    hi_o=x_act(hi_i)\n",
    "    fi_i=np.dot(x_who,hi_o)\n",
    "    fi_o=x_act(fi_i)\n",
    "    return (fi_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.nural(input_l)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"mnist_dataset/mnist_train_100.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "model_path1=os.path.join(os.path.pardir,'models','model_reg.pkl') #path variable where file is stored\n",
    "model_path2=os.path.join(os.path.pardir,'models','model_who.pkl') #path variable where file is stored\n",
    "model_path3=os.path.join(os.path.pardir,'models','model_wih.pkl') #path variable where file is stored\n",
    "#checking the saved model through already available path variable model_path\n",
    "model_pick1=open(model_path1,'rb') #rb means read only in binary format (since its saved in binary not UTF8)\n",
    "model_pick2=open(model_path2,'rb') #rb means read only in bi\n",
    "model_pick3=open(model_path3,'rb') #rb means read only in bi\n",
    "model_load1=pickle.load(model_pick1)\n",
    "x_wih=pickle.load(model_pick3)\n",
    "x_who=pickle.load(model_pick2)\n",
    "model_pick1.close()\n",
    "model_pick2.close()\n",
    "model_pick3.close()\n",
    "model_load1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {} # scores is an empty dict already\n",
    "\n",
    "if os.path.getsize(model_path1) > 0:      \n",
    "    with open(model_path, \"rb\") as model_pick:\n",
    "        model_load = pickle.load(model_pick)\n",
    "        # if file is not empty scores will be equal\n",
    "        # to the value unpickled\n",
    "       # scores = unpickler.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76320365, 0.00214479, 0.0245301 , 0.01291607, 0.03189287,\n",
       "       0.00897646, 0.03526153, 0.20788098, 0.00865457, 0.00234529])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_values = record.split(',')\n",
    "all_val=test_data_list[3].split(',')\n",
    "model_load1((np.asfarray(all_val[1:])/255.0*0.99)+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecards = []\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "# split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    #print(correct_label, \"correct label\")\n",
    "    # scale and shift the inputs\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = model_load1(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = np.argmax(outputs)\n",
    "    #print(label, \"network's answer\")\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "    # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecards.append(1)\n",
    "    else:\n",
    "    # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecards.append(0)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.93\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = np.asarray(scorecards)\n",
    "print (\"performance = \", scorecard_array.sum() /scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
