{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## writting simple nural network for mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.special #here its used for the activation function(writting clear sigmoid fun.)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nuralnetwork:\n",
    "    def __init__(self,inputnode,hiddennodes,outputnodes,learningrate):\n",
    "        self.inode=inputnode\n",
    "        self.onode=outputnodes\n",
    "        self.hnode=hiddennodes\n",
    "        self.lr=learningrate\n",
    "        \n",
    "        #declaration of input to hidden weights (wih) and hidden to output nodes (who) in form of matrices\n",
    "        #the wih matix has hnode rows and inode columns\n",
    "        self.wih=np.random.normal(0.0, pow(self.hnode, -0.5),(self.hnode, self.inode))\n",
    "        self.who=np.random.normal(0.0, pow(self.onode, -0.5),(self.onode, self.hnode))\n",
    "        \n",
    "        #writting the activation function\n",
    "        self.act_fun=lambda x:scipy.special.expit(x)\n",
    "        \n",
    "    def train(self,inputs_list,targets_list):\n",
    "        #convert list to 2D array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        #signals into and out of hidden layer nodes (in form of matrix)\n",
    "        hi_inp=np.dot(self.wih,inputs)\n",
    "        hi_out=self.act_fun(hi_inp)\n",
    "        #signals into and out of final layer\n",
    "        fi_inp=np.dot(self.who,hi_out)\n",
    "        fi_out=self.act_fun(fi_inp)\n",
    "        \n",
    "        output_err=targets-fi_out #error at output layer\n",
    "        hidd_err=np.dot(self.who.T,output_err) #hidden layer error is the output_err,split by weights,\n",
    "        #recombined at hidden nodes\n",
    "        #now we have reached the core or the heart of our network\n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who=self.who+self.lr*np.dot((output_err*fi_out*(1.0-fi_out)),np.transpose(hi_out))\n",
    "        # update the wight for links btw input layer and hidden layer\n",
    "        self.wih+=self.lr*np.dot((hidd_err*hi_out*(1.0-hi_out)),np.transpose(inputs))\n",
    "        \n",
    "    def query(self,inputs_list):\n",
    "        inputs=np.array(inputs_list,ndmin=2).T\n",
    "        \n",
    "        hi_inp=np.dot(self.wih,inputs)\n",
    "        hi_out=self.act_fun(hi_inp)\n",
    "        \n",
    "        fi_inp=np.dot(self.who,hi_out)\n",
    "        fi_out=self.act_fun(fi_inp)\n",
    "        \n",
    "        return (fi_out)\n",
    "    def exit_out(self):\n",
    "        return(self.wih,lambda x:scipy.special.expit(x),self.who)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "# learning rate is 0.2\n",
    "learning_rate = 0.2\n",
    "# create instance of neural network\n",
    "n = nuralnetwork(input_nodes,hidden_nodes,output_nodes,learning_rate)\n",
    "# load the mnist training data CSV file into a list\n",
    "dataset_path=os.path.join(os.path.pardir,\"mnist_dataset/mnist_train.csv\")\n",
    "training_data_file = open(dataset_path, 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "# train the neural network\n",
    "# go through all records in the training data set\n",
    "for i in range(2): #train the whole dataset 2 times\n",
    "    for record in training_data_list:    \n",
    "    # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "    # scale and shift the inputs\n",
    "        inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = np.zeros(output_nodes) + 0.0\n",
    "        # all_values[0] is the target label for this record (this is the desired probability of the one actucal \n",
    "        #number out of 10 numbers in array)\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_wih,x_act,x_who=n.exit_out()\n",
    "def nural(input_l):\n",
    "    x_act=lambda x:scipy.special.expit(x)\n",
    "    inp=np.array(input_l,ndmin=2).T\n",
    "    hi_i=np.dot(x_wih,input_l)\n",
    "    hi_o=x_act(hi_i)\n",
    "    fi_i=np.dot(x_who,hi_o)\n",
    "    fi_o=x_act(fi_i)\n",
    "    return (fi_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "dataset_path=os.path.join(os.path.pardir,\"mnist_dataset/mnist_test.csv\")\n",
    "test_data_file = open(dataset_path, 'r')\n",
    "#test_data_file = open(\"mnist_dataset/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "all_val=test_data_list[77].split(',')\n",
    "print(all_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.99692938e-04, 7.83891986e-03, 9.99537613e-01, 1.08916518e-05,\n",
       "       7.38959413e-08, 2.12611024e-05, 8.22322133e-05, 8.00793262e-03,\n",
       "       4.88049421e-04, 2.43914018e-06])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nural((np.asfarray(all_val[1:])/255.0*0.99)+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.99692938e-04],\n",
       "       [7.83891986e-03],\n",
       "       [9.99537613e-01],\n",
       "       [1.08916518e-05],\n",
       "       [7.38959413e-08],\n",
       "       [2.12611024e-05],\n",
       "       [8.22322133e-05],\n",
       "       [8.00793262e-03],\n",
       "       [4.88049421e-04],\n",
       "       [2.43914018e-06]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query((np.asfarray(all_val[1:])/255.0*0.99)+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0e70753c10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_arr=(np.asfarray(all_val[1:]).reshape(28,28))\n",
    "plt.imshow(img_arr,cmap='Greys',interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "# split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    #print(correct_label, \"correct label\")\n",
    "    # scale and shift the inputs\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = np.argmax(outputs)\n",
    "    #print(label, \"network's answer\")\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "    # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "    # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9651\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() /scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "#import libraries\n",
    "import numpy as np\n",
    "import scipy.special #here its used for the activation function(writting clear sigmoid fun.)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#creating file path\n",
    "model_path=os.path.join(os.path.pardir,'models','model_reg.pkl') #path variable where file is stored\n",
    "model_pathwo=os.path.join(os.path.pardir,'models','model_who.pkl') #path variable where file is stored\n",
    "model_pathwi=os.path.join(os.path.pardir,'models','model_wih.pkl') #path variable where file is stored\n",
    "\n",
    "#open the file to write\n",
    "model_pickle = open(model_path, 'wb') #here wb means we are writting in binary to model_reg.pkl\n",
    "model_picklewo = open(model_pathwo, 'wb') #here wb means we are writting in binary to model_reg.pkl\n",
    "model_picklewi = open(model_pathwi, 'wb') #here wb means we are writting in binary to model_reg.pkl\n",
    "# persist the model in file\n",
    "\n",
    "pickle.dump(nural,model_pickle)\n",
    "x_wih,x_act,x_who\n",
    "pickle.dump(x_wih,model_picklewi)\n",
    "#pickle.dump(x_act,model_pickle)\n",
    "pickle.dump(x_who,model_picklewo)\n",
    "\n",
    "#close the file\n",
    "model_pickle.close()\n",
    "model_picklewi.close()\n",
    "model_picklewo.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nural(input_l):\n",
    "    x_act=lambda x:scipy.special.expit(x)\n",
    "    inp=np.array(input_l,ndmin=2).T\n",
    "    hi_i=np.dot(x_wih,input_l)\n",
    "    hi_o=x_act(hi_i)\n",
    "    fi_i=np.dot(x_who,hi_o)\n",
    "    fi_o=x_act(fi_i)\n",
    "    return (fi_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.nural(input_l)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "dataset_path=os.path.join(os.path.pardir,\"mnist_dataset/mnist_test.csv\")\n",
    "test_data_file = open(dataset_path, 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "model_path1=os.path.join(os.path.pardir,'models','model_reg.pkl') #path variable where file is stored\n",
    "model_path2=os.path.join(os.path.pardir,'models','model_who.pkl') #path variable where file is stored\n",
    "model_path3=os.path.join(os.path.pardir,'models','model_wih.pkl') #path variable where file is stored\n",
    "#checking the saved model through already available path variable model_path\n",
    "model_pick1=open(model_path1,'rb') #rb means read only in binary format (since its saved in binary not UTF8)\n",
    "model_pick2=open(model_path2,'rb') #rb means read only in bi\n",
    "model_pick3=open(model_path3,'rb') #rb means read only in bi\n",
    "model_load1=pickle.load(model_pick1)\n",
    "x_wih=pickle.load(model_pick3)\n",
    "x_who=pickle.load(model_pick2)\n",
    "model_pick1.close()\n",
    "model_pick2.close()\n",
    "model_pick3.close()\n",
    "model_load1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {} # scores is an empty dict already\n",
    "\n",
    "if os.path.getsize(model_path1) > 0:      \n",
    "    with open(model_path, \"rb\") as model_pick:\n",
    "        model_load = pickle.load(model_pick)\n",
    "        # if file is not empty scores will be equal\n",
    "        # to the value unpickled\n",
    "       # scores = unpickler.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99700195e-01, 2.24714983e-05, 1.65834302e-03, 2.11284784e-04,\n",
       "       1.48004902e-04, 2.42722837e-05, 8.70518945e-05, 1.14195145e-03,\n",
       "       3.04319005e-06, 1.99846926e-03])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_values = record.split(',')\n",
    "all_val=test_data_list[3].split(',')\n",
    "model_load1((np.asfarray(all_val[1:])/255.0*0.99)+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecards = []\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "# split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    #print(correct_label, \"correct label\")\n",
    "    # scale and shift the inputs\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = model_load1(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = np.argmax(outputs)\n",
    "    #print(label, \"network's answer\")\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "    # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecards.append(1)\n",
    "    else:\n",
    "    # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecards.append(0)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9651\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = np.asarray(scorecards)\n",
    "print (\"performance = \", scorecard_array.sum() /scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
